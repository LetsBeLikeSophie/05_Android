2021-11-08
------------------------------------

빅데이터 ??

레가시 시스템 (웹 브라우저 시스템 관점에서 레가시 시스템)
단말기 - 메임프레임 


웹 브라우저 시스템 ( 빅데이터 관점에서 레가시 시스템) : 현재 우리가 공부하는 시스템 
브라우저 - 웹서버 - WAS - DataBase 

순차적 프로세스 
-------------------
회원가입 - 회원가입이 완료가 될 때 가지 기달리고 - 완료가 되야 서비스가 끝나지 

브라우저에서 회원정보 입력 - 웹서버 - WAS - JDBC - 데이터베이스에 INSERT
데이터베이스에 INSERT - JDBC - WAS - 웹서버 - 브라우저에 입력 성공 메시지 

영속성 : 퍼시스턴스 
-------------------
브라우저 - 웹서버 여러대 - WAS 여러대 - JDBC Connection풀 - 데이터베이스 여러개 



미국 대선 서비스 
52개주, 2억, 투표율50%, 1억 건 

52개주 게더링된 투표 - 브라우저에서 입력 - 파일이 한개 - 웹서버 여러대 - WAS 여러대 - JDBC Connection풀 - 데이터베이스 여러개


##########################################
처리할 데이터파일이 300기가 

기존 시스템은 
------------------
300기가를 순차적으로 처리한다. 
								


빅데이터 시스템 
미국 대선 서비스 
52개주, 2억, 투표율50%, 1억 건 

52개주 게더링된 투표 - 브라우저에서 입력 - 파일을 필요한 만큼 쪼개서 - 웹서버 여러대 - WAS 여러대 - JDBC Connection풀 - 데이터베이스 여러개

처리할 데이터파일이 300기가 
빅데이터 시스템은  
300기가 
100기가씩 나누어서 처리한다.
컴퓨터가 3대
10기가를 나누어서 처리한다. 
컴퓨가 30대 
단 3대, 30대를 처리할 수 있는 기술이 있으면

==================================
빅데이터는 
-------------------
기존의 
순차적 처리 시스템을 
병렬로 처리하는 시스템으로 변경된 시스템 
in-memory 에서 읽고 쓰기 

Volume	:	데이터의 크기 
		:	대용량 데이터(테라바이트 이상) 수집 <-- 이 당시에는 빅데이터 : 관리자 관점 
		:	대뮤모 메시지(1000TPS 이상) 수집 <-- 현재의 빅데이터 : 디벨롭퍼 관점
==================================

##########################################



빅데이터의 이해
---------------------------------------

2011년 메타그룹(현 가트너) 
Volume		:	데이터의 크기 
			:	대용량 데이터(테라바이트 이상) 수집 <-- 이 당시에는 빅데이터 : 관리자 관점 
			:	대뮤모 메시지(1000TPS 이상) 수집 <-- 현재의 빅데이터 : 디벨롭퍼 관점 

Variety		:	데이터 종류의 다양성 
			:	정형/반정형/비정형 데이터 수집
			:	Log, RSS, XML, 파일, DB, HTML, 음성, 사진, 동영상 등 

Velocity	:	데이터의 입출력 속도  
			:	실시간 스트림 수집 : 3V


Veracity	:	진실성 : IBM 에서 추가 : 4V
			:	데이터의 품짐과 신뢰성을 확보해 적재

Visualization	:	시각화
				:	후처리된 데이터셋을 시각화해서 탐색	

Value	:	가치 : 6V
		:	분석된 결과를 비즈니스에 적요해 가치 창출

빅데이터 6V
크기(Volume) : 방대한 양의 데이터(테라, 페타바이트 이상의 크기)
다양성(Varity) : 정형(DBMS, 전문 등) + 비정형(SNS, 동영상, 사진, 음성, 텍스트 등)
속도(Velocity) : 실시간으로 생상되며, 빠른 속도로 데이터를 처리/분석
진실성(Veracity) : 주요 의사결정을 위해 데이터의 품질과 신뢰성 확보
시각화(Visualization) : 복잡한 대규모 데이터를 시각적으로 표현
가치(Value) : 비즈니스 효익을 실현하기 위해 궁극적인 가차를 창출 

###########################################################
빅데이타는 관점에 따라 차이가 있다.
최고 관리자
중간 관리자 : 빅테이타는 페타 가 넘어야 한다고 하는데 
개발자 : 우리는 개발자 시각 : 현재 시스템에서 처리할 수 없는 
                         데이터의 양 또는 속도가 
		빅데이타의 처리 과정
		분산 파일 처리 
		전통적인 싱글 스레드 방식에서 병렬 처리로 바뀌는 것 
###########################################################

빅데이터 프로젝트
---------------------------------------
플랫폼 구축형 프로젝트
	: 전형적인 빅데이터 SI(System Integeration) 구축형 사업 
	  3 ~ 6개월 정도 소요
	  이중 상당한 리소스가 내/외부 데이터 데이터 수집/적재에 사용
	: 빅데이터의 하드웨어와 소프트웨어를 설치 및 구성하고 
	  빅데이터이 기본 프로세스인 
	  수집 -> 적재 -> 처리 -> 탐색 -> 분석의 기능을 구성
		PM : Project Manager : 관리형 PM 보다 기술형 PM
		아키텍트
		플랫폼 파트 : 설치, 구성 (3 ~ 5명)
		전처리 파트 : 수집, 적재 (3 ~ 5명)
		후처리 파트 : 처리, 탐색, 분석 (3 ~ 5명)

빅데이터 분석 프로젝트
	: 플랫폼 구축 완료 후 6 ~ 12개월 정도 데이터를 모으면서
	  데이터에 대한 이해가 높아지기 시작할 때 진행 한다. 
	  분석 프로젝트의 경우 1 ~ 3개우러로 짧게 수행

	  마케팅 분석 영여
	  상품/서비스 분석 영역
	  리스크 분석 영역

	  프로젝트 관리자
	  비즈니스 
	  데이터 분석 : 해당 비즈니스 를 잘 알아야 한다. 
	  데이터 엔지니어링 : 해당 비즈니스 를 잘 알아야 한다.  

빅데이터 운영 프로젝트 
	완성된 빅데이터 시스템을 중장기적으로 유지 관리하는 프로젝트
	기존의 다른 운영시스템과 비교시 상당한 노력과 운영비용이 발생
	빅데이터를 잘하려면 
	기술과 비지니스 분야에서 전문가 그룹이 받으시 필요한데
	이를 내재화 하지 않고 일련의 시스템처림 
	외주 또는 ITO(IT Outsourcing)에 의존시 곧바로 한계에 부?디치게 된다. 

	CEO
	빅데이터 센터
	빅데이터 부서 
	업무부서1 : 빅데이터 분석 팀 
	업무부서2 : 빅데이터 분석 팀 
	업무부서3 : 빅데이터 분석 팀 


빅데이터 기술의 변화 
---------------------------------------
인프라 스트럭처
	서버 :	x86급의 CPU, 메모리 디스크 등을 장착한 서버 :  HP
			리눅스 운영체제가 설치된 서버(RedHat, CentOs 등) : IBM
	네트워크 : 대규모 빅데이터 서버 및 스토리지 지원을 위한 대용량(10G) 네트워크 : Cisco
	스토리지 : 대규모 데이터를 저장하기 위한 내외부 스토리지 장치 : Dell, RedHat 등	
소프트웨어 플랫폼
	빅데이터의 전방위 기술을 포괄하는 스택 
	(순수 오픈소스 스택 또는 기업 배포판 스택)
	빅데이터 수집/적재/처리/분석 등의 지원 솔루션
	빅데이터 시스템 관리 및 모니터링 툴 제공
	빅데이터 + AI 플랫폼 확장 
		빅데이터 글로벌 BIG3 : 2014년 (2005년 하둡 시작)
			클아우테라(Cloudea), 맵알(MapR), 호튼웍스(HortonWorks)
		KT넥스알, 그루터, 클라우다인 등 
IT 서비스
	빅데이터 컨설팅 및 구축 이행
	빅데이터 전문 운영 및 유지보수
	빅데이터 데이터/분석 서비스
	빅데이터 교육센터 운영 및 인력 양성
		KT DS, LG CNS,  삼성 SDS, SK C&C, 다음소프트 등



빅데이터 구현 기술 
---------------------------------------
수집 -> 적재 -> 처리 및 탐색 -> 분석 및 응용
	처리 및 탐색, 분석 및 응용 단계는 필요시 반복 진행

수집
	내/외부 데이터 연동, 내/외부 데이터 통합
		Crawling, FTP, Open API
		RSS, Log Aggregation
		DB Aggregation, Streaming
적재
	대용량/실시간 데이터 처리, 분산 파일 시스템 저장
		Distrubuted File, No-SQL
		Memory Cached
		Message Queue
처리
	데이터 선택, 변환, 통합, 축소, 데이터 워크플로 및 자동화
		Structuered Processing
		Unstructered Processing
		Workflow, Scheduler
탐색
	대화영 데이트 질의, 탐색적 Ad-Hoc 분석
		SQL Like
		Distributed Programming
		Exploration Visualization
분석
	빅데이터 마트 구성, 통계 분석, 고급 분석
		Data Mining
		Machine Learning
		Analysis visualization
응용	
	보고서 및 시각화, 분석 정보 제공
		Data Export/Import
		Reporting
		Business Visualization


수집 기술
	빅데이터의 수집 기술은 조직의 내외부에 있는 다양한 시스템으로 부터
	원천 데이터를 효과적으로 수집하는 기술이다. 
	빅데이터 수집에는 기존의 수집 시스템(EAI, ETL, EBS 등)에서 다뤘던
	데이터보다 더 크고 다양한 형식의 데이터를 빠르게 처리해야 하는 기능이 필요, 
	이 때문에 빅데이터 수집 아키텍처는 선형확장이 가능하면서 
	분산 처리가 가능한 형태로 구성된다. 

	다양한 인터페이스 유형 : 데이터베이스, 파일, API, 메시지 : 정형 비정형
	외부 데이터 : SNS, 블로그, 포털 등 
	대용량 파일 수집과 실시간 스트림 수집으로 나누며
	실시간 수집의 경우 CEP(Complex Event Processing), 
	ESP(Event Stream Process)  기술이 적용되어 
	수집중인 데이터로부터 이벤트를 감지해 빠른 후속처리를 수행한다. 
	수집된 데이터는 필요 시 정제, 변환, 필터링 등의 추가로 진행해
	데이터의 품질을 향상시킨 후 빅데이터 저장소에 적재된다.
		Crawling, NLP  등 비정형 처리 기술
		Flumne, Fluented, Scribe, Logstash, Chukwa, Nifi, Embulk 등
		실시간 스트림 데이터 처리 스톰(Storm), 에스퍼(Esper) 

적재 기술
	빅데이터 적재 기술은 수집한 데이터를 분산 스토리지에 
	영구 또는 임시로 적재하는 기술이다. 
	빅데이터 분산 저장소로는 크게 4가지 유형이 있다. 
		1. 대용량 파일 전체를 영구적으로 저장 
			HDFS(Hadoop Distributed File System)
		2. 대규모 메시징 데이터 전체를 영구 저장
			NoSQL : HBase, MongoDB, Casandra 등
		3. 대규모 메시지 데이터의 일부만 임시 저장하기 위한 인메모리 캐시
			Redis, Memcached, Infinispan
		4. 대규모 메시지 데이터 전체를 버퍼링 처리
			Message Oriented Middlerware : Kafka, RabbitMQ, ActiveMQ
	빅데이터 적재 기술은 수집된 데이터의 성격에 따라 적재 저장소를 달리하면
	대용량 파일의 적재는 주로 HDFS 저장소를 사용하면 되지만
	실시간 및 대량으로 발생하는 작은 메시지 데이터는 
	관리노드와 병렬처리의 효율성을 위해 NoSQL, 인메모리 캐시, MoM 등을 
	선택적오 사용하는 아키텍처링이 이루어저야 한다. 
	빅데이터가 적재될 때는 추가적인 전처리 작업이  수행되기도 하는데,
	다음에 있는 탐색/분석 단계를 위해 
	비정형(음성, 이미지, 텍스트, 동영상 등)데이터를 정형 데이터(스키마가 있는 구조)로
	가공하거나, 개인정보로 의심되는 데이트를 비식별화 처리하는 작업이 선행된다. 
	이러한 전처치 작업은 데이터의 크기와 비즈니스 요건에 따라 
	HDFS에 적재한 후에 수해하는 후처리 작업으로도 할 수 있다. 

처리 및 탐색 기술
	빅데이터 처리/탐색 기술은 대용량 저장소에 적재된 데이터를 
	분석에 활용하기 위해 데이터를 정형화 및 정규화하는 기술이다. 
	탐색적 분석에는 SQL on Hadoop 이 주로 사용되며,
	대화형 애드훅(AD-Hoc) 쿼리로 데이터를 
	탐색, 선택, 변환, 통합, 축속 등의 작업을 수행한다. 

	특히, 내외부의 정형/비정형 데이터를 결합해 기존의 기술적 한계로
	만들지 못했던 새로운 데이터셋ㅇ르 생성하는 중요한 작업이 진행된다.
	또한 정기적으로 발생하는 처리/탐색의 과정들을
	워크플로(workflow)로 프로세스화해서 자동화하고, 
	워크플로 작업이 끝나면 데이터셋을 특화된 데이터 저장소
	(Dat Warehouse, Mart  emd)로 옮겨지며 
	이 데이터셋은 측적 가능한 구조로 만들어져 있어
	빅데이터 분석을 빠르고 편리하게해준다.
	이 후 후처리 작업과 정규화 과정을 통해 
	이 데이터의 진실성을 확보하고 후 처리된 데이터 셋을
	시각화 툴러 덩욱 용이하게 탐색할 수 있다. 	
		휴(Hue), 하이브(Hive), 스파크(Spark) SQL, 우지(Oozie) 

분석 및 응용 기술
	빅데이터의 분석 기술은 대규모 데이터로부터 새로운 패턴을 찾고, 
	그 패턴을 해석해서 통찰력을 확보하기 위한 기술이다. 
	빅테이터 분석은 활용 영역에 따라
	통계, 데이터 마이닝, 텍스트 마이닝, 소셜 미디어 분석, 
	머신러닝(딥러닝) 등 다양하게 분류된다. 

	빅데이터 용어가 사용되기 이전에도 데이터 분석 기술과 도구가
	많이 사용되고 있었지만 모바일과 소셜 네트워크 서비스, 
	그리고 4차 산업혁명 시기에 접어들면서 생산되는 데이터의 양을
	기존 분석 기술로 처리하는 데 한계가 발생했다.

	빅데이터 분석 기술은 선형적 확자이 가능했고 대규모 분산 환경을 
	낮은 비용으로 구출할 수 있어서 기존 분석 기술의 한계점을 
	극복하고 분산환경 위에서 머신러닝 기술을 구현해 
	군집(clustering), 분류(classification), 회귀(regression), 
	추전(recommendation) 등 고급 분석영역까지 확장 되며
	파일 기반의 배치 분석보다 수십 배나 빠른, 인메모리 기반의 분석 기술이
	빅데이터 생태계에서 빠르게 발전했고 그 활용범위가 커져가고 있다. 
		임팔라(Impala), 제플린(Zeppelin), 머하웃(Mahout), R, 텐서플로(Tensorflow),
		스콥(Sqoop)을 용용해서 외부 RDBMS에 데이터를 제공(Export) 한다. 


빅데이터와 보안
---------------------------------------
	빅데이터 시스템도 일반 시스템에 적용되는 모든 보안 요소
	시스템 보안, 네트워크 보안, 코드 보안 데이터 보안 등을 고려해야 한다. 
데이터 보안
	빅데이터에서 데이터 보안의 원칙은 
	"개인 식별이 가능한 어떠한 정보도 수집하지 않는다"다.
	개인 식별 정보란 
	개인을 식별할 수 있는 고유한 정보로서 
	이름, 직업, 성별, 주민등록번호, 전화번호, 주소, 여권번호, 
	위치 정보 등 매우 다양할 수 있다.
	하지만 이러한 개인 식별 정보를 아예 수집하지 못할 경우 
	빅데이터 분석 자체자 의미없어지므로 개인정보 비식별화 기술로 
	가명처리, 총계처리, 데이터 값 삭제, 범주화, 마스킹 등을 할 수 있다. 
	비식별화된 개인정보를 활용하는데 두가지 이슈가 있다.
	첫 번째는 개인정보 재식별화 
		이름 + 연령대 + 성별 + 거주지 + 직업 + 전화번호 : 포괄적 
		취미 + 차량정보가 결합되면 실제로 유일할 수 있기 때문에 
		특정 개인을 식별할 가능성이 매우 높아진다. 
	두 번째는 개인정보 보호로 인해 개인화된 서비스 또는 마케팅 어려워진다.
		마케팅 활용 동의 여부에 대한 정보는 
		관련 시스템으로부터 최대한 짧은 주기로 수집해 업데이트하고 
		개인 식별 문제는 사회적 식별키
		(이메일, 계좌번호, 전화번호, 주민등록번호, 여권번호, 운전면허정보 등) 대신
		고객관리 시스템에 고유하게 발급하는 대체키
		(대표키, 고객키로 불리면 시스템 내에 유니크한 값으로 생성)를 
		활용해 빅데이터에 적재된 다른 정보화 결합해 사용한다. 
접근제어 보안
	현재 빅데이터 시스템의 접근제어(인증, 권한)을 완벽하게 처리하는 데는
	많은 어려움이 있다. 
	분산 환경의 복잡한 다양한 빅데이터 오픈소스 소프트웨어을 대상으로 
	접근 보안 정책을 적용하기 위해서 오픈소스를 수정하거나 
	유료 버전을 구입해야 하는 상황이 발생할 수 있기 때문이다.
	빅데이터 시스템의 물리적(네트워크) 위치는 대부분 방화벽 안쪽으로
	외부 공격이나 불특정 다수의 접근이 원?덕으로 불가하며,
	비식별화된 데이터로 저장돼 있어 보통의 저수준의 접근제어 정책을
	적용하지만 일부 금융권 및 민감한 개인정보를 다루는 
	빅데이터 시스템의 경우 엄격한 접근제어 정책과 본안 준수를 요구한다.
		아파츠 녹스(Apache Knox)
			직접 접근을 막고 항상 녹스를 커쳐 통신하게 하는 
			중간 게이트웨이 역활을 한다.
		아파치 센트리(Apache Sentry)
			하둡 파일시스템에 상세한 접근 제어 
			(하둡 파일/디렉토리, 하이브 테이블 등)가 필요할 때 사용한다. 
			접근 이력 관리 및 감사 로그 조회 
		아파치 레인지(Apache Ranger)
			플러그인을 통해 레인저 서버와 통신하고 
			센트리와 마찬가지로 접근이력을 관리하는 
			접근 이력 관리 및 감사 로그 조회 
		커버로스(Kerberos)
			KDC(Key Distribution Center) 시스템으로 불린다.
			AS(Autherntication Service) 인증 서버화
			TGS(Ticket Granting Service) 라는 티켓 발행 서버로 구성된다. 
			하둡 파일시스템에 접근하려는 클라이언트 에코시스템은 
			AS 인증 서버를 통해 최초 인증을 수행하고 
			TGS 티켓 발행 서버로부터 하둡 파일시스템에 접근을 
			허용하는 티켓을 발행 받는다.
			이후에는 유효 티케으로 인증없이 접근 할 수 있다 
	실제 프로젝트에서는 
	기존의 계정/통합 관리 시스템(IAM, EAM, LDAP 등)과 
	연동 및 동기화 작업을 통해 구축한다.


인터넷의 빅데이터 : 외부 데이터 (빅데이터에서는) : 아무것나 가져오면 잡혀간다. 돈내라고 한다.
-----------------------------------
블러그와 SNS : 트렌트 부석
	블러그, 웹 사이트에 매일매일 정보 업로드
	페이스북, 트위터 등의 SNS가 퍼지면서 IT 지식이 거의 없는 
	사람들도 다양한 정보를 인터넷에 올리고 수집 분석하면 다양한 트랜드 분석 

인터넷 전자상거래 : 상품 데이터베이스
	쿠팡, 인터파크 등의 인터넷 쇼핑몰 매일 수많은 상품 데이터 업로드
	네이버, 다음 사이트에서 다양한 곳의 상품 데이터를 모아 웹 API로 제공하므로 
	이를 이용하면 상품 데이터를 쉽게 활용

금융정보
	인터넷의 환율, 주식 등 다양한 금융정보 
	국가의 환율, 주식 금값 등을 실시간 추출
	정기적으로 추출해서 저장해두고 활용하면 예측 등에 활용

이미지 데이터
	플리커, 인스타그램 등, 이미지와 함께 제공되는 태그 정보 

행정 기관 정보 : 공개 데이터 : data.go.kr, 전세계 공공데이터(현재 77개 국가에서 지원)
	인구, 지리, 미세먼지, 관광 정보 등 

위키 
	세계 최대 사전 이면서 비교적 자유로운 라이센스를 가지고 있어서 활용 가능 
	한영 사전, 한일 사전, 한중 사정 언어 데이터

저작권이 없어진 작품 
	고전 소설, 고정 그림 등 대부분 다양한게 활용

머신러닝 데이터
	손글씨 이미지 데이터, 사람 얼굴 데이터, 강아지와 고양이 등의 동물 데이터 


스크레이핑, 크롤링, 데이터 가공
-------------------------------------------
Scraping : 스크레이핑
웹 사이트에 있는 특정 정보를 추출하는 기술을 의미한다.
스크레이핑을 이용하면 웹 사이트에 있는 정보를 쉽게 수집 가능 
수집한 HTML 형식을 가공해서 데이터베이스에 저장(구조 분석 포함)
로그인해야 유용한 정보에 접근할 수 있으므로 
로그인에 필요한 웹 페이지 접근 기술 ...

Crawling : 크롤링
프로그램이 웹 사이트를 정기적으로 돌며 정보를 추출하는 기술이다.
클롤링하는 프로그램을 Crawler(클로러) 또는 Spider(스파이더)
검색엔진을 구현할 때 클롤러는 웹 사이트 링크를 타고 돌며 
웹사이트의 데이터를 긁어 데이터베이스에 저장한다. 정기적으로 최신정보 저장 

머신러닝에 사용할 수 있는 데이터 구조
쉼표로 구분하는 형식의 데이터 : CSV
계층을 통해 구조화 하는 형식의 데이터 : JSON, XML, YAML

urllib : 파이선 기본 라이브러리
BeautifulSoup :  HTML, XML 
Reqeusts : 데이터 다운로드 
Selenium : 웹 브라우저 조작 크롤링, 스크레이핑   
Scrapy : 크롤링과 스크레이핑 프레임워크 


Python : 파이썬
-------------------------------------------
과학 데이터 처리, 인공지능, 기계학습, 딥러닝, 
웹프로그래밍, 웹 크롤링, 정보보안, 게임 개발 등의
다양한 분야에서 사용되는 언어이다. 

파이썬 개발도구 
1. python

2대 버전, 3대 버전 두개의 버전이 호환이 않된다.
3대 버전 사용 예정 : 연습할 때는 최신 버전 사용하기 (딥러닝에 문제가 있음)

파이썬 안정화 버전 
3 대 버전 메이저 
3.10
3.9
3.8
3.7 <-- 이 버전 사용하기 
3.5
3.4


https://www.python.org/downloads/ 3.7.6 버전 받기 

Add Python 3.7 to PAHTH :  체크하기 
Install Now  클릭



ERD 작성하기 
------------------------------------
논리모델					물리모델 
Entity(개체)				Talbe
Primary Key(기본키)		Primary Key
Attribute(일반속성)		Column

논리모델 : 개체와 개체의 관계를 표현하는 모델
물리모델 : Table 과 Table의 관계를 표현하는 모델 

식별 관계 : identifying relationship
	부모테이블의 식별키가 자식테이블의 프라이머리키 영역에 FK로 참조되는 경우 
비식별 관계 : non-identifying relationship
	부모테이블의 식별키가 자식테이블의 일반속성 영역에 FK로 참조되는 경우 

ERD 작성 순서
요구사항 분석 완료 후 
1. 논리모델 
2. 테이블 정의서 
3. 물리모델 